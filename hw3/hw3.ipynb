{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Алгоритмы интеллектуальной обработки больших объемов данных\n",
    "## Домашнее задание №3 - Дерево решений\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Общая информация**\n",
    "\n",
    "**Срок сдачи:** 25 ноября 2019, 15:00   \n",
    "**Штраф за опоздание:** -2 балла после 15:00 25 ноября, -4 балла после 15:00 2 декабря, -6 баллов после 15:00 9 декабря  -8 баллов после 15:00 16 декабря.\n",
    "\n",
    "При отправлении ДЗ указывайте фамилию в названии файла Присылать ДЗ необходимо в виде ссылки на свой github репозиторий на почту ml1.sphere@mail.ru с указанием темы в следующем формате:\n",
    "[ML0919, Задание 3] Фамилия Имя. \n",
    "\n",
    "\n",
    "Используйте данный Ipython Notebook при оформлении домашнего задания."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Задание 1 (3 балла)\n",
    "Разберитесь в коде MyDecisionTreeClassifier, который уже частично реализован. Допишите код там, где написано \"Ваш код\". Ваша реализация дерева должна работать по точности не хуже DecisionTreeClassifier из sklearn. Точность проверяется на [wine](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_wine.html) и [Speed Dating Data](https://cloud.mail.ru/public/8nHV/p6J7wY1y1)\n",
    "\n",
    "###### Задание 2 (3 балла)\n",
    "Добиться скорости работы на fit не медленнее чем в 10 раз sklearn на данных wine и Speed Dating Data. \n",
    "Для этого используем numpy.\n",
    "\n",
    "###### Задание 3 (2 балла)\n",
    "Добавьте функционал, который определяет значения feature importance. Выведите 10 главных фичей под пунктом Задание 4 (уже написано ниже) для MyDecisionTreeClassifier и DecisionTreeClassifier так, чтобы сразу были видны выводы и по MyDecisionTreeClassifier, и по DecisionTreeClassifier. Используем данные Speed Dating Data.\n",
    "\n",
    "###### Задание 4 (2 балла)\n",
    "С помощью GridSearchCV или RandomSearchCV подберите наиболее оптимальные параметры для случайного леса (Выберете 2-3 параметра). Используем данные Speed Dating Data. Задание реализуйте под пунктом Задание 5 (уже написано ниже)\n",
    "\n",
    "\n",
    "**Штрафные баллы:**\n",
    "\n",
    "1. Невыполнение PEP8 -1 балл\n",
    "2. Отсутствие фамилии в имени скрипта (скрипт должен называться по аналогии со stroykova_hw3.ipynb) -1 балл\n",
    "3. Все строчки должны быть выполнены. Нужно, чтобы output команды можно было увидеть уже в git'е. В противном случае -1 балл\n",
    "4. При оформлении ДЗ нужно пользоваться данным файлом в качестве шаблона. Не нужно удалять и видоизменять написанный код и текст. В противном случае -1 балл"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.datasets import load_wine\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from sklearn.model_selection import KFold, train_test_split, GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "%matplotlib inline\n",
    "# %load_ext pycodestyle_magic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%pycodestyle\n",
    "\n",
    "\n",
    "class MyDecisionTreeClassifier:\n",
    "    NON_LEAF_TYPE = 0\n",
    "    LEAF_TYPE = 1\n",
    "\n",
    "    def __init__(self, min_samples_split=2, max_depth=None, sufficient_share=1.0,\n",
    "                 criterion='gini', max_features=None):\n",
    "        self.tree = dict()\n",
    "        self.impurities = dict()\n",
    "        self.min_samples_split = min_samples_split\n",
    "        self.max_depth = max_depth\n",
    "        self.sufficient_share = sufficient_share\n",
    "        self.num_class = -1\n",
    "        self.feature_importances_ = None\n",
    "        if criterion == 'gini':\n",
    "            self.G_function = self.__gini\n",
    "        elif criterion == 'entropy':\n",
    "            self.G_function = self.__entropy\n",
    "        elif criterion == 'misclass':\n",
    "            self.G_function = self.__misclass\n",
    "        else:\n",
    "            print('invalid criterion name')\n",
    "            raise\n",
    "\n",
    "        if max_features == 'sqrt':\n",
    "            self.get_feature_ids = self.__get_feature_ids_sqrt\n",
    "        elif max_features == 'log2':\n",
    "            self.get_feature_ids = self.__get_feature_ids_log2\n",
    "        elif max_features == None:\n",
    "            self.get_feature_ids = self.__get_feature_ids_N\n",
    "        else:\n",
    "            print('invalid max_features name')\n",
    "            raise\n",
    "    \n",
    "    def __gini(self, l_c, l_s, r_c, r_s):\n",
    "        l_s = l_s.astype('float')\n",
    "        r_s = r_s.astype('float')\n",
    "        return (l_s * (1 - np.sum((l_c / l_s) ** 2, axis=1)).reshape(-1, 1) +\n",
    "                r_s * (1 - np.sum((r_c / r_s) ** 2, axis=1)).reshape(-1, 1)) / (l_s + r_s)\n",
    "\n",
    "    def __entropy(self, l_c, l_s, r_c, r_s):\n",
    "        return (l_s * (-np.sum((l_c / l_s) * np.log((l_c) / l_s), axis=1)).reshape(-1, 1) +\n",
    "                r_s * (-np.sum((r_c / r_s) * np.log((r_c) / r_s), axis=1)).reshape(-1, 1)) / (l_s + r_s)\n",
    "\n",
    "    def __misclass(self, l_c, l_s, r_c, r_s):\n",
    "        return (l_s * (1 - np.max(l_c / l_s, axis=1)).reshape(-1, 1) +\n",
    "                r_s * (1 - np.max(r_c / r_s, axis=1)).reshape(-1, 1)) / (l_s + r_s)\n",
    "\n",
    "    def __get_feature_ids_sqrt(self, n_feature):\n",
    "        feature_ids = list(range(n_feature))\n",
    "        np.random.shuffle(feature_ids)\n",
    "        return feature_ids[:int(np.ceil(np.sqrt(n_feature)))]\n",
    "        \n",
    "    def __get_feature_ids_log2(self, n_feature):\n",
    "        feature_ids = list(range(n_feature))\n",
    "        np.random.shuffle(feature_ids)\n",
    "        return feature_ids[:int(np.ceil(np.log2(n_feature)))]\n",
    "\n",
    "    def __get_feature_ids_N(self, n_feature):\n",
    "        return list(range(n_feature))\n",
    "    \n",
    "    def __sort_samples(self, x, y):\n",
    "        sorted_idx = x.argsort()\n",
    "        return x[sorted_idx], y[sorted_idx]\n",
    "\n",
    "    def __div_samples(self, x, y, feature_id, threshold):\n",
    "        left_mask = x[:, feature_id] > threshold\n",
    "        right_mask = ~left_mask\n",
    "        return x[left_mask], x[right_mask], y[left_mask], y[right_mask]\n",
    "\n",
    "    def __find_threshold(self, x, y):\n",
    "        x_sort, y_sort = self.__sort_samples(x, y)\n",
    "\n",
    "        class_brd = np.where(y_sort[:-1] != y_sort[1:])[0] + 1\n",
    "\n",
    "        if len(class_brd) == 0:\n",
    "            return np.inf, None\n",
    "\n",
    "        eq_el_count = class_brd - np.append([0], class_brd[:-1])\n",
    "        one_hot_code = np.zeros((class_brd.shape[0], self.num_class))\n",
    "        one_hot_code[np.arange(class_brd.shape[0]), y_sort[class_brd - 1]] = 1\n",
    "        class_increments = one_hot_code * eq_el_count.reshape(-1, 1)\n",
    "\n",
    "        l_c = np.cumsum(class_increments, axis=0)\n",
    "        r_c = np.bincount(y, minlength=self.num_class) - l_c\n",
    "        l_s = class_brd.reshape(l_c.shape[0], 1)\n",
    "        r_s = y_sort.shape[0] - l_s\n",
    "\n",
    "        gs = self.G_function(l_c, l_s, r_c, r_s)\n",
    "        idx = np.argmin(gs)\n",
    "\n",
    "        left_el_id = l_s[idx][0]\n",
    "        return gs[idx], (x_sort[left_el_id - 1] + x_sort[left_el_id]) / 2.0\n",
    "\n",
    "    def __fit_node(self, x, y, node_id, depth):\n",
    "        n_features = x.shape[1]\n",
    "        bins = np.bincount(y)\n",
    "        \n",
    "        if (depth == self.max_depth \\\n",
    "            or y.shape[0] < self.min_samples_split \\\n",
    "            or np.unique(y).shape[0] == 1 \\\n",
    "            or bins.max() >= self.sufficient_share * y.shape[0]):\n",
    "            \n",
    "            self.tree[node_id] = (self.LEAF_TYPE, bins.argmax(), bins.max() / n_features)\n",
    "        else:\n",
    "            feature_ids = self.get_feature_ids(n_features)\n",
    "            thresholds = np.array([self.__find_threshold(x[:, idx], y) for idx in feature_ids])\n",
    "            best_thresh_id = thresholds[:, 0].argmin()\n",
    "            \n",
    "            impurity, threshold = thresholds[best_thresh_id]\n",
    "            x_l, x_r, y_l, y_r = self.__div_samples(x, y, feature_ids[best_thresh_id], threshold)\n",
    "            \n",
    "            if node_id:\n",
    "                impurities = self.impurities[(node_id - 1) // 2]\n",
    "                self.feature_importances_[best_thresh_id] += \\\n",
    "                    impurities[0] - impurities[1][node_id % 2] * impurity\n",
    "            else:\n",
    "                self.feature_importances_[best_thresh_id] += 1 - impurity\n",
    "            \n",
    "            if y_l.shape[0] == 0 or y_r.shape[0] == 0:\n",
    "                self.tree[node_id] = (self.LEAF_TYPE, bins.argmax(), bins.max() / n_features)\n",
    "            else:\n",
    "                self.tree[node_id] = (self.NON_LEAF_TYPE, best_thresh_id, threshold)\n",
    "                self.impurities[node_id] = (impurity, np.array([y_l.shape[0], y_r.shape[0]]) / y.shape[0])\n",
    "                self.__fit_node(x_l, y_l, 2 * node_id + 1, depth + 1)\n",
    "                self.__fit_node(x_r, y_r, 2 * node_id + 2, depth + 1)\n",
    "            \n",
    "    \n",
    "    def fit(self, x, y):\n",
    "        self.feature_importances_ = np.zeros(x.shape[1])\n",
    "        \n",
    "        self.num_class = np.unique(y).size\n",
    "        self.__fit_node(x, y, 0, 0)\n",
    "        \n",
    "        self.feature_importances_ /= self.feature_importances_.sum()\n",
    "\n",
    "    def __predict_class(self, x, node_id):\n",
    "        node = self.tree[node_id]\n",
    "        if node[0] == self.__class__.NON_LEAF_TYPE:\n",
    "            _, feature_id, threshold = node\n",
    "            if x[feature_id] > threshold:\n",
    "                return self.__predict_class(x, 2 * node_id + 1)\n",
    "            else:\n",
    "                return self.__predict_class(x, 2 * node_id + 2)\n",
    "        else:\n",
    "            return node[1]\n",
    "\n",
    "    def __predict_probs(self, x, node_id):\n",
    "        node = self.tree[node_id]\n",
    "        if node[0] == self.__class__.NON_LEAF_TYPE:\n",
    "            _, feature_id, threshold = node\n",
    "            if x[feature_id] > threshold:\n",
    "                return self.__predict_probs(x, 2 * node_id + 1)\n",
    "            else:\n",
    "                return self.__predict_probs(x, 2 * node_id + 2)\n",
    "        else:\n",
    "            return node[2]\n",
    "        \n",
    "    def predict(self, X):\n",
    "        return np.array([self.__predict_class(x, 0) for x in X])\n",
    "    \n",
    "    def predict_probs(self, X):\n",
    "        return np.array([self.__predict_probs(x, 0) for x in X])\n",
    "\n",
    "    def fit_predict(self, x_train, y_train, predicted_x):\n",
    "        self.fit(x_train, y_train)\n",
    "        return self.predict(predicted_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_clf = MyDecisionTreeClassifier(min_samples_split=2)\n",
    "clf = DecisionTreeClassifier(min_samples_split=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "wine = load_wine()\n",
    "X_train, X_test, y_train, y_test = train_test_split(wine.data, wine.target, test_size=0.1, stratify=wine.target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Проверка скорости работы на wine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.95 ms, sys: 0 ns, total: 1.95 ms\n",
      "Wall time: 1.54 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "                       max_features=None, max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, presort=False,\n",
       "                       random_state=None, splitter='best')"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 15 ms, sys: 0 ns, total: 15 ms\n",
      "Wall time: 14.1 ms\n"
     ]
    }
   ],
   "source": [
    "%time my_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Проверка качества работы на wine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8885003885003885"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_pred=clf.predict(X_test), y_true=y_test, average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9440559440559441"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_pred=my_clf.predict(X_test), y_true=y_test, average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.04864194, 0.09754123, 0.        , 0.        , 0.05487926,\n",
       "       0.        , 0.29003717, 0.        , 0.        , 0.17216971,\n",
       "       0.        , 0.04136954, 0.29536115])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_clf.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.00442139, 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.20573053, 0.        , 0.        , 0.36036196,\n",
       "       0.        , 0.03260394, 0.39688217])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.feature_importances_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Подготовка данных Speed Dating Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./data/speed-dating-experiment/Speed Dating Data.csv', encoding='latin1')\n",
    "\n",
    "df = df.iloc[:, :97]\n",
    "df = df.drop(['id'], axis=1)\n",
    "df = df.drop(['idg'], axis=1)\n",
    "df = df.drop(['condtn'], axis=1)\n",
    "df = df.drop(['round'], axis=1)\n",
    "df = df.drop(['position', 'positin1'], axis=1)\n",
    "df = df.drop(['order'], axis=1)\n",
    "df = df.drop(['partner'], axis=1)\n",
    "\n",
    "df = df.drop(['age_o', 'race_o', 'pf_o_att', \n",
    "              'pf_o_sin', 'pf_o_int',\n",
    "              'pf_o_fun', 'pf_o_amb', 'pf_o_sha',\n",
    "              'dec_o', 'attr_o', 'sinc_o', 'intel_o', 'fun_o',\n",
    "              'amb_o', 'shar_o', 'like_o', 'prob_o','met_o'], \n",
    "             axis=1)\n",
    "\n",
    "df = df.dropna(subset=['age'])\n",
    "df.loc[:, 'field_cd'] = df.loc[:, 'field_cd'].fillna(19)\n",
    "df = df.drop(['field'], axis=1)\n",
    "\n",
    "df = df.drop(['undergra'], axis=1)\n",
    "\n",
    "df.loc[:, 'mn_sat'] = df.loc[:, 'mn_sat'].str.replace(',', '').astype(np.float)\n",
    "df.loc[:, 'mn_sat'] = df.loc[:, 'mn_sat'].fillna(df.mn_sat.min())\n",
    "\n",
    "df.loc[:, 'tuition'] = df.loc[:, 'tuition'].str.replace(',', '').astype(np.float)\n",
    "df.loc[:, 'mn_sat'] = df.loc[:, 'mn_sat'].fillna(df.tuition.min())\n",
    "\n",
    "df = df.dropna(subset=['imprelig', 'imprace'])\n",
    "\n",
    "df = df.drop(['from', 'zipcode'], axis=1)\n",
    "\n",
    "df.loc[:, 'income'] = df.loc[:, 'income'].str.replace(',', '').astype(np.float)\n",
    "df.loc[:, 'income'] = df.loc[:, 'income'].fillna(df.income.min())\n",
    "\n",
    "df = df.dropna(subset=['date'])\n",
    "\n",
    "df.loc[:, 'career_c'] = df.loc[:, 'career_c'].fillna(18)\n",
    "df = df.drop(['career'], axis=1)\n",
    "\n",
    "df = df.drop(['sports', 'tvsports', 'exercise', 'dining', 'museums', \n",
    "              'art', 'hiking', 'gaming', 'clubbing', 'reading', 'tv', \n",
    "              'theater', 'movies', 'concerts', 'music', 'shopping', 'yoga'], axis=1)\n",
    "\n",
    "df = df.drop(['expnum'], axis=1)\n",
    "\n",
    "df.loc[:, 'temp_totalsum'] = \\\n",
    "    df.loc[:, ['attr1_1', 'sinc1_1', 'intel1_1', 'fun1_1', 'amb1_1', 'shar1_1']].sum(axis=1)\n",
    "df.loc[:, ['attr1_1', 'sinc1_1', 'intel1_1', 'fun1_1', 'amb1_1', 'shar1_1']] = \\\n",
    "    (df.loc[:, ['attr1_1', 'sinc1_1', 'intel1_1', 'fun1_1', 'amb1_1', 'shar1_1']].T / \n",
    "     df.loc[:, 'temp_totalsum'].T).T * 100\n",
    "\n",
    "df.loc[:, 'temp_totalsum'] = \\\n",
    "    df.loc[:, ['attr2_1', 'sinc2_1', 'intel2_1', 'fun2_1', 'amb2_1', 'shar2_1']].sum(axis=1)\n",
    "df.loc[:, ['attr2_1', 'sinc2_1', 'intel2_1', 'fun2_1', 'amb2_1', 'shar2_1']] = \\\n",
    "    (df.loc[:, ['attr2_1', 'sinc2_1', 'intel2_1', 'fun2_1', 'amb2_1', 'shar2_1']].T /\n",
    "     df.loc[:, 'temp_totalsum'].T).T * 100\n",
    "\n",
    "df = df.drop(['temp_totalsum'], axis=1)\n",
    "\n",
    "for i in [4, 5]:\n",
    "    feat = ['attr{}_1'.format(i), 'sinc{}_1'.format(i), \n",
    "            'intel{}_1'.format(i), 'fun{}_1'.format(i), \n",
    "            'amb{}_1'.format(i), 'shar{}_1'.format(i)]\n",
    "    \n",
    "    if i != 4:\n",
    "        feat.remove('shar{}_1'.format(i))\n",
    "    \n",
    "    df = df.drop(feat, axis=1)\n",
    "    \n",
    "df = df.drop(['wave'], axis=1)\n",
    "\n",
    "df_male = df.query('gender == 1').drop_duplicates(subset=['iid', 'pid'])\\\n",
    "                                 .drop(['gender'], axis=1)\\\n",
    "                                 .dropna()\n",
    "df_female = df.query('gender == 0').drop_duplicates(subset=['iid'])\\\n",
    "                                   .drop(['gender', 'match', 'int_corr', 'samerace'], axis=1)\\\n",
    "                                   .dropna()\n",
    "df_female.columns = df_female.columns + '_f'\n",
    "\n",
    "df_final = df_male.join(df_female.set_index('iid_f'), on='pid', how='inner')\n",
    "df_final = df_final.drop(['iid', 'pid', 'pid_f'], axis=1)\n",
    "\n",
    "X = df_final.loc[:, df_final.columns != 'match'].to_numpy()\n",
    "y = df_final.match.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>match</th>\n",
       "      <th>int_corr</th>\n",
       "      <th>samerace</th>\n",
       "      <th>age</th>\n",
       "      <th>field_cd</th>\n",
       "      <th>mn_sat</th>\n",
       "      <th>tuition</th>\n",
       "      <th>race</th>\n",
       "      <th>imprace</th>\n",
       "      <th>imprelig</th>\n",
       "      <th>...</th>\n",
       "      <th>sinc2_1_f</th>\n",
       "      <th>intel2_1_f</th>\n",
       "      <th>fun2_1_f</th>\n",
       "      <th>amb2_1_f</th>\n",
       "      <th>shar2_1_f</th>\n",
       "      <th>attr3_1_f</th>\n",
       "      <th>sinc3_1_f</th>\n",
       "      <th>fun3_1_f</th>\n",
       "      <th>intel3_1_f</th>\n",
       "      <th>amb3_1_f</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>3489</td>\n",
       "      <td>0</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>1450.0</td>\n",
       "      <td>26100.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3498</td>\n",
       "      <td>0</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1155.0</td>\n",
       "      <td>13258.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3507</td>\n",
       "      <td>0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1430.0</td>\n",
       "      <td>26908.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3516</td>\n",
       "      <td>0</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1140.0</td>\n",
       "      <td>9168.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3534</td>\n",
       "      <td>0</td>\n",
       "      <td>0.23</td>\n",
       "      <td>1</td>\n",
       "      <td>27.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1360.0</td>\n",
       "      <td>26062.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8112</td>\n",
       "      <td>0</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1450.0</td>\n",
       "      <td>26908.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>25.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8178</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.24</td>\n",
       "      <td>1</td>\n",
       "      <td>24.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1320.0</td>\n",
       "      <td>25533.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>...</td>\n",
       "      <td>25.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8200</td>\n",
       "      <td>0</td>\n",
       "      <td>0.12</td>\n",
       "      <td>1</td>\n",
       "      <td>23.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1309.0</td>\n",
       "      <td>15162.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>...</td>\n",
       "      <td>25.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8222</td>\n",
       "      <td>0</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1430.0</td>\n",
       "      <td>26908.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>25.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8354</td>\n",
       "      <td>0</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1400.0</td>\n",
       "      <td>26019.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>25.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1190 rows × 63 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      match  int_corr  samerace   age  field_cd  mn_sat  tuition  race  \\\n",
       "3489      0      0.43         0  27.0      16.0  1450.0  26100.0   2.0   \n",
       "3498      0      0.46         0  28.0       8.0  1155.0  13258.0   2.0   \n",
       "3507      0      0.05         0  32.0       7.0  1430.0  26908.0   2.0   \n",
       "3516      0      0.44         0  25.0      10.0  1140.0   9168.0   2.0   \n",
       "3534      0      0.23         1  27.0       8.0  1360.0  26062.0   6.0   \n",
       "...     ...       ...       ...   ...       ...     ...      ...   ...   \n",
       "8112      0      0.48         0  24.0       5.0  1450.0  26908.0   2.0   \n",
       "8178      0     -0.24         1  24.0       5.0  1320.0  25533.0   4.0   \n",
       "8200      0      0.12         1  23.0       5.0  1309.0  15162.0   4.0   \n",
       "8222      0      0.31         0  24.0       5.0  1430.0  26908.0   2.0   \n",
       "8354      0      0.09         0  27.0       8.0  1400.0  26019.0   1.0   \n",
       "\n",
       "      imprace  imprelig  ...  sinc2_1_f  intel2_1_f  fun2_1_f  amb2_1_f  \\\n",
       "3489      2.0       3.0  ...        1.0         1.0       3.0      10.0   \n",
       "3498      8.0       9.0  ...        1.0         1.0       3.0      10.0   \n",
       "3507      1.0       6.0  ...        1.0         1.0       3.0      10.0   \n",
       "3516      7.0       1.0  ...        1.0         1.0       3.0      10.0   \n",
       "3534      1.0       1.0  ...        1.0         1.0       3.0      10.0   \n",
       "...       ...       ...  ...        ...         ...       ...       ...   \n",
       "8112      5.0       1.0  ...       25.0        10.0      10.0       5.0   \n",
       "8178      9.0       6.0  ...       25.0        10.0      10.0       5.0   \n",
       "8200      3.0       8.0  ...       25.0        10.0      10.0       5.0   \n",
       "8222      7.0       1.0  ...       25.0        10.0      10.0       5.0   \n",
       "8354      2.0       1.0  ...       25.0        10.0      10.0       5.0   \n",
       "\n",
       "      shar2_1_f  attr3_1_f  sinc3_1_f  fun3_1_f  intel3_1_f  amb3_1_f  \n",
       "3489       10.0        7.0        7.0       8.0         8.0      10.0  \n",
       "3498       10.0        7.0        7.0       8.0         8.0      10.0  \n",
       "3507       10.0        7.0        7.0       8.0         8.0      10.0  \n",
       "3516       10.0        7.0        7.0       8.0         8.0      10.0  \n",
       "3534       10.0        7.0        7.0       8.0         8.0      10.0  \n",
       "...         ...        ...        ...       ...         ...       ...  \n",
       "8112       25.0        6.0       10.0       9.0         7.0       5.0  \n",
       "8178       25.0        6.0       10.0       9.0         7.0       5.0  \n",
       "8200       25.0        6.0       10.0       9.0         7.0       5.0  \n",
       "8222       25.0        6.0       10.0       9.0         7.0       5.0  \n",
       "8354       25.0        6.0       10.0       9.0         7.0       5.0  \n",
       "\n",
       "[1190 rows x 63 columns]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_clf = MyDecisionTreeClassifier(min_samples_split=2, max_features='sqrt')\n",
    "clf = DecisionTreeClassifier(min_samples_split=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Проверка скорости работы на Speed Dating Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 19.2 ms, sys: 0 ns, total: 19.2 ms\n",
      "Wall time: 18.2 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "                       max_features=None, max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, presort=False,\n",
       "                       random_state=None, splitter='best')"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 18.4 ms, sys: 44 µs, total: 18.4 ms\n",
      "Wall time: 17.8 ms\n"
     ]
    }
   ],
   "source": [
    "%time my_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Проверка качества работы на Speed Dating Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5306432038834952"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_pred=clf.predict(X_test), y_true=y_test, average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ayakovenko/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.45662100456621"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_pred=my_clf.predict(X_test), y_true=y_test, average='macro')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задание 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задание 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_names = df_final.loc[:, df_final.columns != 'match'].columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MyDecisionTreeClassifier importances\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'tuition': 0.29415787333753457,\n",
       " 'age': 0.1777563236979994,\n",
       " 'int_corr': 0.17427630023606414,\n",
       " 'field_cd': 0.1566489282958818,\n",
       " 'samerace': 0.07875024900151749,\n",
       " 'imprace': 0.061196962092827885,\n",
       " 'race': 0.05721336333817472,\n",
       " 'attr1_1_f': 0.0,\n",
       " 'exphappy_f': 0.0,\n",
       " 'career_c_f': 0.0}"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('MyDecisionTreeClassifier importances')\n",
    "d = {}\n",
    "for idx in np.argsort(-my_clf.feature_importances_)[:10]:\n",
    "    d[col_names[idx]] = my_clf.feature_importances_[idx]\n",
    "\n",
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTreeClassifier importances\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'int_corr': 0.0859416660662911,\n",
       " 'attr2_1': 0.05422552053579554,\n",
       " 'shar1_1_f': 0.053878758507275804,\n",
       " 'income_f': 0.049955026864601015,\n",
       " 'income': 0.028956468123186915,\n",
       " 'attr2_1_f': 0.028794517787253886,\n",
       " 'sinc1_1': 0.027073449585290184,\n",
       " 'amb3_1_f': 0.02532633751424487,\n",
       " 'race': 0.025228310952999936,\n",
       " 'samerace': 0.025023711028150538}"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('DecisionTreeClassifier importances')\n",
    "d = {}\n",
    "for idx in np.argsort(-clf.feature_importances_)[:10]:\n",
    "    d[col_names[idx]] = clf.feature_importances_[idx]\n",
    "\n",
    "d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задание 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'criterion': ['gini', 'entropy'],\n",
    "    'max_depth': np.arange(1, 10),\n",
    "    'min_samples_leaf': np.arange(1, 6)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ayakovenko/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_split.py:1978: FutureWarning: The default value of cv will change from 3 to 5 in version 0.22. Specify it explicitly to silence this warning.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n",
      "/home/ayakovenko/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_search.py:266: UserWarning: The total space of parameters 90 is smaller than n_iter=200. Running 90 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  % (grid_size, self.n_iter, grid_size), UserWarning)\n",
      "/home/ayakovenko/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_search.py:814: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv='warn', error_score='raise-deprecating',\n",
       "                   estimator=DecisionTreeClassifier(class_weight=None,\n",
       "                                                    criterion='gini',\n",
       "                                                    max_depth=None,\n",
       "                                                    max_features=None,\n",
       "                                                    max_leaf_nodes=None,\n",
       "                                                    min_impurity_decrease=0.0,\n",
       "                                                    min_impurity_split=None,\n",
       "                                                    min_samples_leaf=1,\n",
       "                                                    min_samples_split=2,\n",
       "                                                    min_weight_fraction_leaf=0.0,\n",
       "                                                    presort=False,\n",
       "                                                    random_state=None,\n",
       "                                                    splitter='best'),\n",
       "                   iid='warn', n_iter=200, n_jobs=-1,\n",
       "                   param_distributions={'criterion': ['gini', 'entropy'],\n",
       "                                        'max_depth': array([1, 2, 3, 4, 5, 6, 7, 8, 9]),\n",
       "                                        'min_samples_leaf': array([1, 2, 3, 4, 5])},\n",
       "                   pre_dispatch='2*n_jobs', random_state=None, refit=True,\n",
       "                   return_train_score=False, scoring='f1', verbose=0)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = DecisionTreeClassifier()\n",
    "random_search = RandomizedSearchCV(model, param_distributions=param_grid, n_iter=200, n_jobs=-1, scoring='f1')\n",
    "random_search.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'min_samples_leaf': 2, 'max_depth': 9, 'criterion': 'gini'}"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7702299455853958"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_pred=random_search.best_estimator_.predict(X_test), y_true=y_test, average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
